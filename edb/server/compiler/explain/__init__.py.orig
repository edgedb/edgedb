#
# This source file is part of the EdgeDB open source project.
#
# Copyright 2016-present MagicStack Inc. and the EdgeDB authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#


from __future__ import annotations
from typing import *

import json
import logging
import pickle
import uuid

from edb.common import ast
from edb.common import context as pctx
from edb.common import debug

from edb.edgeql import ast as qlast

from edb.ir import ast as irast

from edb.schema import constraints as s_constr
from edb.schema import indexes as s_indexes
from edb.schema import objects as so
from edb.schema import pointers as s_pointers
from edb.schema import schema as s_schema

from edb.pgsql import ast as pgast
from edb.pgsql.compiler import astutils

from . import casefold
from . import coarse_grained
from . import fine_grained
from . import ir_analyze
from . import pg_tree
from . import to_json


log = logging.getLogger(__name__)


# "affects_compilation" config vals that we don't actually want to report out.
# This turns out to be a majority of them
OMITTED_CONFIG_VALS = {
    "allow_dml_in_functions", "allow_bare_ddl", "force_database_error",
}

<<<<<<< HEAD
# Finds all the direct descendents of the given plan node that have been
# annotated with 'Contexts', and creates a new collapsed tree of those under
# the 'collapsed_plans' key.
# Also for 'Aggregate' type plan nodes, that do not already have 'Contexts',
# try to find the nearest descendent plan node with 'Contexts' and
# attach that as 'NearestContextPlan'.
# The original plan tree remains under the 'plans' key, but plan nodes
# de-duplicated as so:
# - Plan node in 'nearest_context_plan' replaced with 0
# - Plan nodes in 'collapsed_plans' replaced with their 1-based index in the
#   'collapsed_plans' list.
def collapse_plan(
    plan: Any,
    find_nearest_ctx: bool = False
) -> Any:
    subplans = []
    found_nearest = None

    unvisited = [(subplan, plan) for subplan in plan.get('plans', [])]
    while unvisited:
        subplan, parent = unvisited.pop(0)
        if 'contexts' in subplan:
            if find_nearest_ctx and found_nearest is None:
                found_nearest = subplan
                parent['plans'][parent['plans'].index(subplan)] = 0
            else:
                subplans.append(subplan)
                parent['plans'][parent['plans'].index(subplan)] = len(subplans)

            collapse_plan(subplan)
        else:
            if subplan['node_type'] == "Aggregate":
                nearest_plan = collapse_plan(subplan, True)
                if nearest_plan:
                    subplan['nearest_context_plan'] = nearest_plan
                    subplans.append(subplan)
                    parent['plans'][parent['plans'].index(subplan)] = (
                        len(subplans))
            else:
                unvisited += [
                    (subsubplan, subplan) for subsubplan
                    in subplan.get('plans', [])
                ]

    if subplans or found_nearest:
        all_subplans = (
            (list(subplans) if subplans else []) +
            (found_nearest.get('collapsed_plans', []) if found_nearest else [])
        )
        if 'full_total_time' in plan:
            plan['collapsed_self_time'] = plan['full_total_time'] - (
                sum([subplan['full_total_time'] for subplan in all_subplans])
            )
        plan['collapsed_self_cost'] = plan['total_cost'] - (
            sum([subplan['total_cost'] for subplan in all_subplans])
        )

    if subplans:
        plan['collapsed_plans'] = subplans

        # For each plan with contexts, try to pick the widest context that the
        # plan node does not share with sibling or parent nodes, to suggest
        # for display in UI
        parent_ctxs = (found_nearest['contexts'] if
                       found_nearest else plan.get('contexts'))
        ctx_subplans = [
            subplan.get('nearest_context_plan') or subplan
            for subplan in subplans
        ]
        for subplan in ctx_subplans:
            plan_ctxs = subplan['contexts']
            sibling_ctxs = list(parent_ctxs) if parent_ctxs else []
            for sib_plan in ctx_subplans:
                if sib_plan != subplan:
                    sibling_ctxs += sib_plan['contexts']
            selected_ctx = None
            if sibling_ctxs:
                for ctx in reversed(plan_ctxs):
                    if not ctx_in_ctxs(ctx, sibling_ctxs):
                        selected_ctx = ctx
                        break

            subplan['suggested_display_ctx_idx'] = (
                plan_ctxs.index(selected_ctx) if selected_ctx
                else len(plan_ctxs) - 1
            )

    return found_nearest


def ctx_in_ctxs(ctx: Any, ctxs: Any) -> bool:
    for c in ctxs:
        if (c['buffer_idx'] == ctx['buffer_idx']
                and c['start'] == ctx['start']
                and c['end'] == ctx['end']):
            return True
    return False

=======
>>>>>>> 0c9848dd8 (WIP naming cleanup)

def analyze_explain_output(
    query_asts_pickled: bytes,
    data: list[list[bytes]],
    std_schema: s_schema.FlatSchema,
) -> bytes:
    if debug.flags.edgeql_explain:
        debug.header('Explain')

    ql: qlast.Base
    ir: irast.Statement
    pg: pgast.Base
    ql, ir, pg, config_vals = pickle.loads(query_asts_pickled)
    schema = ir.schema
    # We omit the std schema when serializing, so put it back
    if isinstance(schema, s_schema.ChainedSchema):
        schema = s_schema.ChainedSchema(
            top_schema=schema._top_schema,
            global_schema=schema._global_schema,
            base_schema=std_schema
        )

    assert len(data) == 1 and len(data[0]) == 1
    plan = json.loads(data[0][0])
    assert len(plan) == 1
    plan = debug_plan = plan[0]['Plan']

    if debug.flags.edgeql_explain:
        import importlib
        importlib.reload(pg_tree)
        importlib.reload(ir_analyze)
        importlib.reload(fine_grained)
        importlib.reload(coarse_grained)

    debug_tree = None
    fg_tree = None
    cg_tree = None
    try:
        info = ir_analyze.analyze_queries(ql, ir, pg, schema=schema)
        debug_tree = pg_tree.Plan.from_json(plan, schema)
        fg_tree, index = fine_grained.build(debug_tree, info)
        if debug.flags.edgeql_explain:
            debug.dump(fg_tree)
            debug.dump(info)
        cg_tree = coarse_grained.build(fg_tree, info, index)
    except Exception as e:
        log.exception("Error building explain model", exc_info=e)

    config_vals = {
        k: v for k, v in config_vals.items() if k not in OMITTED_CONFIG_VALS
    }
    globals_used = sorted([str(k) for k in ir.globals])

    output = {
        'buffers': info.buffers,
        'config_vals': config_vals,
        'globals_used': globals_used,
        'debug_info': {
            'full_plan': debug_tree,
            'alias_info': info,
        },
        'fine_grained': fg_tree,
        'coarse_grained': cg_tree,
    }
    #if debug.flags.edgeql_explain:
    #    debug.dump(output)

    return json.dumps(output, default=to_json.json_hook).encode('utf-8')


